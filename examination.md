## 1. Свойства и области применения искусственных нейронных сетей (ИНС).


## 2. Структура и свойства искусственного нейрона.
Искуственный нейрон представляет собой аналог упрощенного биологического нейрона, и являтся структурным элементом искусственной нейронной сети. Можно предстввить как сумматор всех входящих сигналов, умноженных на некоторый коэфициент (вес синаптической связи), и применяющий к результату активационную функцию.  
Состоит из:
1. Синапса (уможнение входа на вес)
2. Сумматора (суммирование полученных значений)
3. Активационной функции (применение к сумме передаточной функции)

Синапсические связи с положительными весами - возбужающие, с отрицательными - тормозящие 

Нейроны можно классифицировать на основе их положения в нейронной сети:  
* Входные нейроны
* Выходные нейроны
* Промежуточные нейроны

Сумма входов:  
$$
S = \sum_{i=0}^{n}  x_i  \omega_i
$$

Активационные функции:

1. Линейная:  
$$  
f(x) = 
\begin{cases}
   0 &\text{if } x \le 0 \\
   1 &\text{if } x \ge 1 \\
   x &\text{else}
\end{cases} 
$$  

2. Пороговая (функция Хевисайда):  
$$  
f(x) = 
\begin{cases}
   1 &\text{if } x \le T \\
   0 &\text{else}
\end{cases}
$$

3. Сигмоидальная:  
$$  
f(x) = {1 \over  1 + e^{-\alpha x}}
$$  


## 3. Классификация искусственных нейронных сетей (в зависимости от: топологии, однородности нейронов, типа сигналов, динамики распространения сигналов по сети, числа слоев, принципа действия).
**Классификация в зависимости от топологии:**
1. Полносвязные  
Нейрон сети связан со всеми нейронами находящихся сети
2. Многослойные
    1. Монотонные  
    Каждый слой разбит на 2 блока: возбуждающий и тормозящий. Связи между блоками также разделяются на тормозящие и возбуждающие. Выходной сигнал каждого блока является монотонно невозрастащий или неубывающей функцией.  
    2. Сети без обратных связей
    3. Сети с обратными связями
        - Слоисто циклические  
        слои замкнуты в кольцо, последний слой передает свои выходные сигналы первому; вс слои равноправны и могут как получать выходные синалы так и выдавать выходыне синналы  
        - Слоисто-полносвязные  
        состоят из слоев каждый из коорых представляет собой полносвязную сеть, а сигналы передаются как от слоя к слою так и внутри слоя  
        - Полносвязанно-слоистые
3. Слабосвязые
    - С окресностью фон Неймана
    - С окрестностью Голея
    - С окрестностью Мура

**Классификация в зависимости от однородности нейронов**
1. Гомогенные ИНС  
состоят из нейронов одного типа с единой функцией активации
2. Гетерогенные ИНС  
состоят из нейронов одного типа с различными функциями активации

**Классификация в зависимости от типа сигналов**
1. Бинарные ИНС  
оперируют только двоичными сигналами
2. Непрерывные ИНС  
оперирут непрерывными (многоградационными ) значениями сигналов

**Классификация в зависимости от динамики распространения сигналов по сети**
1. Синхронные ИНС  
нейроны всей сети меняют свое сотояние в отдельное моменты времени которое является константой и равно у всех нейронов 
2. Асинхронные ИНС  
нейроны такой сети меняют свое состояние в моменты времени которое вляется постоянным но не равно у всех нейронов

**Классификация в зависимости от числа слоев**
1. Однослойнные ИНС  
сети с одним скрытым слоем нейронов
2. Многослойные ИНС  
сети с двумя и более серытыми слоями нейронов

**Классификация в зависимости от принципа действия**
1. формальные ИНС
2. релаксационные ИНС
3. имитаторы ИНС

## 4. Теоремы Колмогорова–Арнольда. Теорема Хехт-Нильсена. Следствия из теорем Колмогорова–Арнольда и Хехт-Нильсена.


## 5. Задачи обучения искусственных нейронных сетей. Постановка задачи обучения ИНС. Классификация методов обучения ИНС. 
Обучение ИНС - процесс, настройки параметров нейронной сети. С математической точке зрения представляет собой задачу оптимизации многомерной функции (нахождение минимумов ошибки при разных значениях параметров нейронной сети).  

Можно классифицировать методы обучения, по изменению парматров нейронной сети:  
- Детерминированный  
Итеративно корректирует параметры сети, основываясь на ее текущих параметрах, величинах входов, фактических и желаемых выходов. Например метод обратного распространения ошибки.
- Стохастический  
Парметры изменяются случайным образом. При этом сохраняются парматры которые привели к улучшению.  
Так же можно различить алгоритмы как
- обучение с учителем;
- обучение без учителя.  

## 6. Однослойный персептрон (структура, алгоритм обучения).
Структура:  
![Однослойный перцептрон](https://github.com/192vlad192/intNet_examination/blob/main/%D0%9E%D0%B4%D0%BD%D0%BE%D1%81%D0%BB%D0%BE%D0%B9%D0%BD%D1%8B%D0%B9%20%D0%BF%D0%B5%D1%80%D1%86%D0%B5%D0%BF%D1%82%D1%80%D0%BE%D0%BD.png)  

Состоит из:
1. Входов;  
2. Одного слоя нейронов.  


## 7. Многослойный персептрон (структура, алгоритм обучения).

Состоит из:
1. S элементов  
    слой сенсоров (рецепторов) может находится в состоянии покоя, возбуждения, торможения {0,1,-1}.
2. A элементов  
    слой называется ассоциативным, поскольку каждому элементу A соответствует набор элементов S.  Сумма значений такой ассоциации акиврует передачу в R если превышена некая величина.  Сигнал в R передается с некоторым коэфициентом.
3. R элемента  
    
Обучение состоит из:
1. изменения весовых коэфициентов A-R. 
2. изменения весов связей S-A (могу принимать значения  {0,1,-1})
3. указания значения порогов A, выбираюся случайныи образом в начале и затем не изменяются.



## 8. Алгоритм обратного распространения ошибки (описание, ограничения).
Алгоритм обратного распространения ошибки —  алгоритм обучения нейронных сетей прямого распространения (многослойных персептронов). Относится к методам обучения с учителем.  
В основе алгоритма лежит использование выходной ошибки нейронной сети
$$
E = {1 \over 2}\sum_{i=1}^k(y-y^{'})^2
$$  
E=1/2∑_{i=1}^{k} (y−y′)^2

Для вычисления величин коррекции весов нейронов в ее скрытых слоях, где k — число выходных нейронов сети, y — целевое значение, y′ — фактическое выходное значение. Алгоритм является итеративным, веса нейронов сети корректируются после подачи на ее вход одного обучающего примера.  
На каждой итерации происходит два прохода сети — прямой и обратный. На прямом входной вектор распространяется от входов сети к ее выходам и формирует некоторый выходной вектор, соответствующий текущему (фактическому) состоянию весов. Затем вычисляется ошибка нейронной сети как разность между фактическим и целевым значениями. На обратном проходе эта ошибка распространяется от выхода сети к ее входам, и производится коррекция весов нейронов в соответствии с правилом:  
$$
\Delta\omega_{i,j}(n) = -\eta{\partial E_{av} \over \partial \omega_{ij}}
$$
Δw_j,i(n)=−η(∂E_av/∂w_ij), (1)

где wj,i — вес i-й связи j-го нейрона, η — параметр скорости обучения, который позволяет дополнительно управлять величиной шага коррекции Δwj,i с целью более точной настройки на минимум ошибки и подбирается экспериментально в процессе обучения (изменяется в интервале от 0 до 1).  
Учитывая, что выходная сумма j-го нейрона равна  
$$  
S_i = \sum_{i=1}^{n}\omega_{ij}x_{i}  
$$  
Sj=n∑i=1wijxi,  
можно показать, что  
$$  
{\partial E \over \partial \omega_{ij}} = { \partial E \over \partial S_j} {\partial S_j \over \partial \omega_{ij}} = x_i {\partial E \over \partial S_j}  
$$  
∂E/∂wij=∂E∂/Sj ∂Sj/∂wij=xi ∂E/∂Sj.    

Из последнего выражения следует, что дифференциал ∂Sj активационной функции нейронов сети f(s) должен существовать и не быть равным нулю в любой точке, т.е. активационная функция должна быть дефференцируема на всей числовой оси. Поэтому для применения метода обратного распространения используют сигмоидальные активационные функции, например, логистическую или гиперболический тангенс.  
Таким образом, алгоритм использует так называемый стохастический градиентный спуск, «продвигаясь» в многомерном пространстве весов в направлении антиградиента с целью достичь минимума функции ошибки.  
На практике обучение продолжают не до точной настройки сети на минимум функции ошибки, а до тех пор, пока не будет достигнуто достаточно точное его приближение. Это позволит, с одной стороны, уменьшить число итераций обучения, а с другой — избежать переобучения сети.  
Преимуществам алгоритма обратного распространения ошибки относятся простота реализации и устойчивость к аномалиям и выбросам в данных. К недостаткам можно отнести:
- неопределенно долгий процесс обучения;
- возможность «паралича сети», когда при больших значениях рабочая точка активационной функции оказывается в области насыщения сигмоиды и производная в выражении (1) становится близкой к 0, а коррекции весов практически не происходит и процесс обучения «замирает»;
- уязвимость алгоритма к попаданию в локальные минимумы функции ошибки.

## 9. Обучение без учителя. Сигнальный и дифференциальный методы обучения Хебба.


## 10. Нейронные сети Кохонена (назначение, особенности, алгоритм обучения, проблемы и пути их решения).


## 11. Нейронные сети встречного распространения (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 12. Нейронные сети радиальных базисных функций (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 13. Каскадные искусственные нейронные сети (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 14. Нейронные сети Хопфилда (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 15. Нейронные сети Хэмминга (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 16. Двунаправленная ассоциативная память (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 17. Сети адаптивной резонансной теории (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 18. Когнитрон (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 19. Неокогнитрон (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 20. Сверточные нейронные сети (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 21. Рекуррентные сети типа LSTM (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 22. Сопоставление интеллектуальных технологий (моделей). Методы гибридизации интеллектуальных технологий (моделей). 
