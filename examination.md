## 1. Свойства и области применения искусственных нейронных сетей (ИНС).


## 2. Структура и свойства искусственного нейрона.
Искуственный нейрон представляет собой аналог упрощенного биологического нейрона, и являтся структурным элементом искусственной нейронной сети. Можно предстввить как сумматор всех входящих сигналов, умноженных на некоторый коэфициент (вес синаптической связи), и применяющий к результату активационную функцию.  
Состоит из:
1. Синапса (уможнение входа на вес)
2. Сумматора (суммирование полученных значений)
3. Активационной функции (применение к сумме передаточной функции)

Синапсические связи с положительными весами - возбужающие, с отрицательными - тормозящие 

Нейроны можно классифицировать на основе их положения в нейронной сети:  
* Входные нейроны
* Выходные нейроны
* Промежуточные нейроны

Сумма входов:  
![2_1](https://github.com/192vlad192/intNet_examination/blob/main/scrin/2_1.jpg)  
Активационные функции:  
1. Линейная:  
![2_2](https://github.com/192vlad192/intNet_examination/blob/main/scrin/2_2.jpg)    
2. Пороговая (функция Хевисайда):  
![2_3](https://github.com/192vlad192/intNet_examination/blob/main/scrin/2_3.jpg)    
3. Сигмоидальная:  
![2_4](https://github.com/192vlad192/intNet_examination/blob/main/scrin/2_4.jpg)  


## 3. Классификация искусственных нейронных сетей (в зависимости от: топологии, однородности нейронов, типа сигналов, динамики распространения сигналов по сети, числа слоев, принципа действия).
**Классификация в зависимости от топологии:**
1. Полносвязные  
Нейрон сети связан со всеми нейронами находящихся сети
2. Многослойные
    1. Монотонные  
    Каждый слой разбит на 2 блока: возбуждающий и тормозящий. Связи между блоками также разделяются на тормозящие и возбуждающие. Выходной сигнал каждого блока является монотонно невозрастащий или неубывающей функцией.  
    2. Сети без обратных связей
    3. Сети с обратными связями
        - Слоисто циклические  
        слои замкнуты в кольцо, последний слой передает свои выходные сигналы первому; вс слои равноправны и могут как получать выходные синалы так и выдавать выходыне синналы  
        - Слоисто-полносвязные  
        состоят из слоев каждый из коорых представляет собой полносвязную сеть, а сигналы передаются как от слоя к слою так и внутри слоя  
        - Полносвязанно-слоистые
3. Слабосвязые
    - С окресностью фон Неймана
    - С окрестностью Голея
    - С окрестностью Мура

**Классификация в зависимости от однородности нейронов**
1. Гомогенные ИНС  
состоят из нейронов одного типа с единой функцией активации
2. Гетерогенные ИНС  
состоят из нейронов одного типа с различными функциями активации

**Классификация в зависимости от типа сигналов**
1. Бинарные ИНС  
оперируют только двоичными сигналами
2. Непрерывные ИНС  
оперирут непрерывными (многоградационными ) значениями сигналов

**Классификация в зависимости от динамики распространения сигналов по сети**
1. Синхронные ИНС  
нейроны всей сети меняют свое сотояние в отдельное моменты времени которое является константой и равно у всех нейронов 
2. Асинхронные ИНС  
нейроны такой сети меняют свое состояние в моменты времени которое вляется постоянным но не равно у всех нейронов

**Классификация в зависимости от числа слоев**
1. Однослойнные ИНС  
сети с одним скрытым слоем нейронов
2. Многослойные ИНС  
сети с двумя и более серытыми слоями нейронов

**Классификация в зависимости от принципа действия**
1. формальные ИНС
2. релаксационные ИНС
3. имитаторы ИНС

## 4. Теоремы Колмогорова–Арнольда. Теорема Хехт-Нильсена. Следствия из теорем Колмогорова–Арнольда и Хехт-Нильсена.
**Теоремы Колмогорова–Арнольда**  
- теорема о возможности представления непрерывных функций нескольких переменных суперпозициями непрерывных функций меньшего числа переменных (1956 г.)  
- теорема о представлении любой непрерывной функции трех переменных в виде суммы функций не более двух переменных (1957 г.)  
- теорема о представлении непрерывных функций нескольких переменных в виде суперпозиций непрерывных функций одного переменного и сложения (1957 г)  

**Теорема Хехт-Нильсена**  
Теорема о представлении непрерывных функций нескольких переменных в виде суперпозиций непрерывных функций одного переменного и сложения для нейронных сетей.  
Доказывает свою представимость функции многих переменных достаточно общего вида с помощью двухслойной нейронной сети с прямыми полными связями с n нейронами входного слоя, (2n+1) нейронами скрытого слоя с заранее известными ограниченнными функциями активации (например сигмоидальными) и m нейронами выходного слоя с неизвестными функциями активации  


**Теорема Колмогорова–Арнольда и Хехт-Нильсена** 
Из теоремы Колмогорова–Арнольда–Хехт–Нильсена (КАХН) следует, что для любой функции многих переменных существует отображающая ее НС фиксированной размерности, при настройке (обучении) которой могут использоваться три степени свободы:
- область значений сигмоидальных функций активации нейронов скрытого слоя;
- наклон сигмоид нейронов этого слоя;
- вид функций активации нейронов выходного слоя.


Следствие 1.  
Из теоремы Хех_Нильсена следует представимость любой многомерной функции нескольких переменных с помощью нейронной сети с фиксированной размерности.  
Неизвестными остаются следующие зарактеристики функции активации нейронов:  
- ограничения области значений сигмоидальных функций активаций нейронов скрытого слоя
- наклон сигмоидальных функций активации 
- вид функции активации нейронов выходного слоя  

Следствие 2.  
Для любого множества пар (X* Y*)  где Y* скаляр, существует двухслойная однородная сеть первого порядка с последовательными связями и с конечным числом нейронов, которая выполняет отображение X->Y, выдаавая на каждый входной сигнал X^k правильный вызодной сигнал Y^k. Нейроны в такой двухслойной нейронной сети должны иместь сигмоидальные передаточные функции.  
Теорема о полноте  
Любая непрерывная функция на замкнутом ограниченном множестве может быть равномерно приближна функциями, вычисляемыми нейронными сетями, если функция активации нейрона дважды непрерывно дифферицируема и непрерывна.  

## 5. Задачи обучения искусственных нейронных сетей. Постановка задачи обучения ИНС. Классификация методов обучения ИНС. 
Обучение ИНС - процесс, настройки параметров нейронной сети. С математической точке зрения задача обучения искусственной нейронной сети представляет собой задачу оптимизации многомерной функции (нахождение минимумов ошибки при разных значениях параметров нейронной сети).  

Можно классифицировать методы обучения, по изменению парматров нейронной сети:  
- Детерминированный  
Итеративно корректирует параметры сети, основываясь на ее текущих параметрах, величинах входов, фактических и желаемых выходов. Например метод обратного распространения ошибки.
- Стохастический  
Парметры изменяются случайным образом. При этом сохраняются парматры которые привели к улучшению.  
  
Так же можно различить алгоритмы как
- обучение с учителем  
процесс заключается в предоставлении данных нейронной сети и сравнении результата работы и соответствующего целевое выходного значение. Далее, при необходимости производится модификация парметров сети и производится повторная проверка.  
![обучение с учителем](https://github.com/192vlad192/intNet_examination/blob/main/scrin/len_with_t.png)  
- обучение без учителя  


## 6. Однослойный персептрон (структура, алгоритм обучения).
Перцептрон — простейший вид нейронных сетей, в основе которого лежит математическая модель восприятия информации мозгом.  
Состоит из:
1. S элементов (сенсорный элемент) 
    слой сенсоров (рецепторов) может находится в состоянии покоя, возбуждения {0,1}.  
    связь между S и A может иметь вес {0,1,-1}.  
2. A элементов (асоциативный элемент) 
    слой называется ассоциативным, поскольку каждому элементу A соответствует набор элементов S.  Сумма значений такой ассоциации акиврует передачу в R 1 если превышена некая величина. Сигнал в R передается с некоторым коэфициентом (любые значения).  
3. R элемента (реагирующий элемент)  
   Суммирует сигналы с A элементов, если порог превышен 1, иначе -1  
   
**Однослойный перцептрон**  
   перцептрон, каждый S-элемент которого однозначно соответствует одному А-элементу, S-A связи всегда имеют вес 1, а порог любого А-элемента равен 1. Часть однослойного персептрона соответствует модели искусственного нейрона.   

Структура:  
![Однослойный перцептрон](https://github.com/192vlad192/intNet_examination/blob/main/scrin/one_l_p.jpg)  

**Алгоритм обучения:**  
Задача обучения состовляет в определении коэфициентов w обеспечивающих заданную ошибку.  
1. Задаются шаг обучения α(0< α <1) и желаемая среднеквадратичная ошибка сети Em.
2. Инициализируются случайным образом весовые коэффициенты w_ij (от i-го к j-тому) и пороговые bi значения R элементов.
3. Подаются последовательно образы из обучающей выборки на вход нейронной сети. Вычисляется выходные значения нейронов.
4. Вычисляется суммарная ошибка нейронной сети E 
5. Если E>Em, то производится изменение весовых коэффициентов и порогов нейронных элементов и выполняется переход к шагу 3, иначе выполнение алгоритма завершается


## 7. Многослойный персептрон (структура, алгоритм обучения).
Перцептрон — простейший вид нейронных сетей, в основе которого лежит математическая модель восприятия информации мозгом.  
Состоит из:
1. S элементов (сенсорный элемент) 
    слой сенсоров (рецепторов) может находится в состоянии покоя, возбуждения {0,1}.  
    связь между S и A может иметь вес {0,1,-1}.  
2. A элементов (асоциативный элемент) 
    слой называется ассоциативным, поскольку каждому элементу A соответствует набор элементов S.  Сумма значений такой ассоциации акиврует передачу в R 1 если превышена некая величина. Сигнал в R передается с некоторым коэфициентом (любые значения).  
3. R элемента (реагирующий элемент)  
   Суммирует сигналы с A элементов, если порог превышен 1, иначе -1  

**Многослойный перцептрон**
   перцептрон, в котором присутствуют дополнительные слои A-элементов, причём, обучение такой сети проводится по методу обратного распространения ошибки, и обучаемыми являются все слои перцептрона (в том числе S—A).

**Алгоритм обучения:**  
1. Задаются шаг обучения α (0< α <1) и желаемая среднеквадратичная ошибка сети Em  
2. Инициализируются случайным образом весовые коэффициенты w_i,j_k(от i-го к j-тому k-го слоя) и пороговые bjk (j-ое k-го слоя) значения НС.
3. Подаются последовательно образы из обучающей выборки на вход нейронной сети. При этом для каждого образа выполняются следующие действия:
    1. Производится фаза прямого распространения входного образа по нейронной сети. Вычисляется выходное значение всех нейронов Yjk.
    2. Вычисляются ошибки Υj нейронов выходного и скрытого слоев.
    3. Производится изменение весовых коэффициентов и порогов нейронных элементов для каждого слоя нейронной сети.
4. Вычисляется суммарная ошибка нейронной сети E
5. Если E>Em, то происходит переход к шагу 3, иначе выполнение алгоритма завершается


## 8. Алгоритм обратного распространения ошибки (описание, ограничения).
Алгоритм обратного распространения ошибки —  алгоритм обучения нейронных сетей прямого распространения (многослойных персептронов). Относится к методам обучения с учителем.  
В основе алгоритма лежит использование выходной ошибки нейронной сети  
![8_1](https://github.com/192vlad192/intNet_examination/blob/main/scrin/8_1.jpg)  

Для вычисления величин коррекции весов нейронов в ее скрытых слоях, где k — число выходных нейронов сети, y — целевое значение, y′ — фактическое выходное значение. Алгоритм является итеративным, веса нейронов сети корректируются после подачи на ее вход одного обучающего примера.  
На каждой итерации происходит два прохода сети — прямой и обратный. На прямом входной вектор распространяется от входов сети к ее выходам и формирует некоторый выходной вектор, соответствующий текущему (фактическому) состоянию весов. Затем вычисляется ошибка нейронной сети как разность между фактическим и целевым значениями. На обратном проходе эта ошибка распространяется от выхода сети к ее входам, и производится коррекция весов нейронов в соответствии с правилом:  
![8_2](https://github.com/192vlad192/intNet_examination/blob/main/scrin/8_2.jpg)   

где wj,i — вес i-й связи j-го нейрона, η — параметр скорости обучения, который позволяет дополнительно управлять величиной шага коррекции Δwj,i с целью более точной настройки на минимум ошибки и подбирается экспериментально в процессе обучения (изменяется в интервале от 0 до 1).  
Учитывая, что выходная сумма j-го нейрона равна  
![8_3](https://github.com/192vlad192/intNet_examination/blob/main/scrin/8_3.jpg)  

можно показать, что  
![8_4](https://github.com/192vlad192/intNet_examination/blob/main/scrin/8_4.jpg)   

Из последнего выражения следует, что дифференциал ∂Sj активационной функции нейронов сети f(s) должен существовать и не быть равным нулю в любой точке, т.е. активационная функция должна быть дефференцируема на всей числовой оси. Поэтому для применения метода обратного распространения используют сигмоидальные активационные функции, например, логистическую или гиперболический тангенс.  
Таким образом, алгоритм использует так называемый стохастический градиентный спуск, «продвигаясь» в многомерном пространстве весов в направлении антиградиента с целью достичь минимума функции ошибки.  
На практике обучение продолжают не до точной настройки сети на минимум функции ошибки, а до тех пор, пока не будет достигнуто достаточно точное его приближение. Это позволит, с одной стороны, уменьшить число итераций обучения, а с другой — избежать переобучения сети.  
Преимуществам алгоритма обратного распространения ошибки относятся простота реализации и устойчивость к аномалиям и выбросам в данных. К недостаткам можно отнести:
- неопределенно долгий процесс обучения;
- возможность «паралича сети», когда при больших значениях рабочая точка активационной функции оказывается в области насыщения сигмоиды и производная в выражении (1) становится близкой к 0, а коррекции весов практически не происходит и процесс обучения «замирает»;
- уязвимость алгоритма к попаданию в локальные минимумы функции ошибки.

## 9. Обучение без учителя. Сигнальный и дифференциальный методы обучения Хебба.
При предъявлении входных образов сеть самоорганизуется посредством настройки своих весов согласно определенному алгоритму. Вследствие отсутствия указания требуемого выхода в процессе обучения результаты непредсказуемы с точки зрения определения возбуждающих образов для конкретных нейронов. При этом, однако, сеть организуется в форме, отражающей существенные характеристики обучающего набора. Например, входные образы могут быть классифицированы согласно степени их сходства так, что образы одного класса активизируют один и тот же выходной нейрон.  
**Алгоритм обучения Хебба**
Хэбб предположил, что синаптическое соединение двух нейронов усиливается, если оба эти нейрона возбуждены. Это можно представить как усиление синапса в соответствии с корреляцией уровней возбужденных нейронов, соединяемых данным синапсом. По этой причине алгоритм обучения Хэбба иногда называется корреляционным алгоритмом.  
Идея алгоритма выражается следующим равенством:  
![9_1](https://github.com/192vlad192/intNet_examination/blob/main/scrin/9_1.jpg)  

NET - уровень возбуждения нейрона  

**Сигнальный метод обучения Хебба**  
Сигнальный метод обучения Хебба заключается в изменении весов по следующему правилу: 
![9_2](https://github.com/192vlad192/intNet_examination/blob/main/scrin/9_2.jpg)  

**Дифференциальный метод обучения Хебба**
Дифференциальный метод обучения Хебба заключается в изменении весов по следующему правилу: 
![9_3](https://github.com/192vlad192/intNet_examination/blob/main/scrin/9_3.jpg)  

## 10. Нейронные сети Кохонена (назначение, особенности, алгоритм обучения, проблемы и пути их решения).


## 11. Нейронные сети встречного распространения (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 12. Нейронные сети радиальных базисных функций (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 13. Каскадные искусственные нейронные сети (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 14. Нейронные сети Хопфилда (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 15. Нейронные сети Хэмминга (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 16. Двунаправленная ассоциативная память (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 17. Сети адаптивной резонансной теории (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 18. Когнитрон (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 19. Неокогнитрон (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 20. Сверточные нейронные сети (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 21. Рекуррентные сети типа LSTM (назначение, особенности, алгоритм обучения, достоинства и недостатки).


## 22. Сопоставление интеллектуальных технологий (моделей). Методы гибридизации интеллектуальных технологий (моделей). 
